{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Plot Ridge coefficients as a function of the regularization\n",
    "\n",
    "\n",
    "Shows the effect of collinearity in the coefficients of an estimator.\n",
    "\n",
    ".. currentmodule:: sklearn.linear_model\n",
    "\n",
    ":class:`Ridge` Regression is the estimator used in this example.\n",
    "Each color represents a different feature of the\n",
    "coefficient vector, and this is displayed as a function of the\n",
    "regularization parameter.\n",
    "\n",
    "This example also shows the usefulness of applying Ridge regression\n",
    "to highly ill-conditioned matrices. For such matrices, a slight\n",
    "change in the target variable can cause huge variances in the\n",
    "calculated weights. In such cases, it is useful to set a certain\n",
    "regularization (alpha) to reduce this variation (noise).\n",
    "\n",
    "When alpha is very large, the regularization effect dominates the\n",
    "squared loss function and the coefficients tend to zero.\n",
    "At the end of the path, as alpha tends toward zero\n",
    "and the solution tends towards the ordinary least squares, coefficients\n",
    "exhibit big oscillations. In practise it is necessary to tune alpha\n",
    "in such a way that a balance is maintained between both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ill-conditioned system of equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author: Fabian Pedregosa -- <fabian.pedregosa@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# X is the 1000x1000 Hilbert matrix\n",
    "X = 1. / (np.arange(1, 1001) + np.arange(0, 1000)[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display upper left corner of X matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[1:6,1:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute right hand side as sum of coefficients across each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y = np.ones(10)\n",
    "y = np.sum(X,axis=1)\n",
    "y[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "alphas = np.logspace(-10, -2, n_alphas)\n",
    "clf = linear_model.Ridge(fit_intercept=False)\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    clf.set_params(alpha=a)\n",
    "    clf.fit(X, y)\n",
    "    coefs.append(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the first 100 coefficients from the ridge regression (should be all ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefs[1][1:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try the same thing with ordinary multiple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "linreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the first 100 coefficients (should be all ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linreg.coef_[1:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
