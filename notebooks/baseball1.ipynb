{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Baseball Databank with pandas\n",
    "\n",
    "In this notebook we will use the very powerful pandas package to examine the Baseball Databank.\n",
    "\n",
    "First we need to import the usual packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np               #standard imports:  numpy, scipy, pandas, matplotlib\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "                                 #the command below allows us to capture matplotlib output in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time Setup\n",
    "\n",
    "Here are instructions for downloading the Baseball Databank.\n",
    "\n",
    "Like so many things these days, the most up-to-date version is on Github.  \n",
    "\n",
    "Open a command promt and cd into the directory you have been issuing your \"git clone\" commands from\n",
    "\n",
    "Once you are in that directory, type:\n",
    "\n",
    "git clone https://github.com/chadwickbureau/baseballdatabank.git\n",
    "\n",
    "This will create a subdirectory called \"baseballdatabank\" that contains the most recent version.\n",
    "\n",
    "We should be able to access the files using a relative path:   ../../baseballdatabank/core\n",
    "\n",
    "This says \"go up two directory levels from where we are, then look in the \"core\" subdirectory of the \"baseballdatabank\" directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can issue commands as if they were typed in at a terminal window with the \"!\" operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! ls -l ../../baseballdatabank/core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are on windows and this doesn't work, try this instead:\n",
    "\n",
    "  !  dir ..\\baseballdatabank\\core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a pandas DataFrame from a .csv file - very easy!\n",
    "\n",
    "The read_csv() function in pandas is the go-to method if your data is in comma separated values (.csv) format.\n",
    "\n",
    "The .csv files in this collection have the column names in the first row, which is often the case (but not always)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read the Master.csv file using a relative path to locate it, and call the pandas DataFrame \"Master\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master = pd.read_csv(\"../../baseballdatabank/core/Master.csv\")   #read Master.csv \n",
    "\n",
    "type(Master)                                                  #show the python type for the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science, most of the effort is spent exploring the data, discovering its characteristics, and massaging it into a form that you can apply modeling techniques to.\n",
    "\n",
    "Jupyter is a great tool for this because you can make up the code piece-by-piece as you discover things about the data, rather than having to know in advance how you should process the data.\n",
    "\n",
    "It's not realistic to expect that you will know enough about the data at the start to completely specify what you need to do to clean it up and make it ready for analysis.\n",
    "\n",
    "We'll start with some really basic things like listing the column names (in this case, they were read from the first row in Master.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master.columns               #list the column names of a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the quickest ways to learn about the content of a DataFrame is to print a few rows.\n",
    "\n",
    "The \"head()\" \"tail()\" methods allow you to do this without writing code.\n",
    "\n",
    "In object oriented programming terminology, these are \"methods\" that the pandas.core.frame.DataFrame \"class\" provides.\n",
    "\n",
    "To use them, you have to specify an \"instance\" of pandas.core.frame.DataFrame for them to operate on.\n",
    "\n",
    "In this case, we want them to operate on the DataFrame we created from Master.csv, which we called \"Master\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our first look at the data.\n",
    "\n",
    "One thing that jumps out is the \"playerID\" column, which seems to contain a kind of mish-mash of the player's name and a number.\n",
    "\n",
    "It's a pretty good bet that this is some kind of unique identifier for that player.\n",
    "\n",
    "Columns that contain unique identifiers play an important role in the \"data wrangling\" phase of the analysis, and we want to make sure pandas knows which columns have this property.\n",
    "\n",
    "We make pandas aware by designating this column as an index.\n",
    "\n",
    "Having learned something from our first peek at the data, let's go back and reread it but this time designate \"playerID\" as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master = pd.read_csv(\"../../baseballdatabank/core/Master.csv\",   #read Master.csv and designate \"playerID\" as an index\n",
    "                     index_col=[\"playerID\"])\n",
    "type(Master)                                                  #show the python type for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it looks like nothing changed, internally pandas now knows that the playerID column contains unique identifiers.\n",
    "\n",
    "This will allow pandas to make intelligent decisions when we want to merge tables together.\n",
    "\n",
    "You can see from the output of the \"ls -l\" command that we are working with a collection of files, and we will amlost certainly need to merge them together at some point.\n",
    "\n",
    "These merge operations will rely on matching up the unique values in an index.\n",
    "\n",
    "Our experience with playerID is a good illustration of why a Jupyter notebook is well-suited to data exploration.\n",
    "\n",
    "We didn't know playerID was a good candidate for an index column until we had seen the data.\n",
    "\n",
    "Once we had seen it, we decided to go back and redo the read_csv() sligthly differently.\n",
    "\n",
    "This is pretty much the nature of \"data munging\", it's not a straight path from start to finish, but a series of discoveries that often lead us to back up and redo things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a DataFrame with describe()\n",
    "\n",
    "Keep in mind pandas was designed from the ground up for \"data wrangling\", also known as \"data_munging\".\n",
    "\n",
    "Usually this is where most of the work happens in any project that involves a lot of raw data.\n",
    "\n",
    "Many people who have experience working with data say that as a rule of thumb, this will be 90% of the overal effort.\n",
    "\n",
    "pandas includes a nice method called \"describe()\" designed to save time in the data exploration stage by automatically summarizing all of the numerical columns in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe() method gives us mean, min, quartiles, max, standard deviation, and count.\n",
    "\n",
    "count is the number of non-missing values.  Note that the counts vary quite a bit, indicating that this data has a lot of missing values.\n",
    "\n",
    "Discovering what values are missing and deciding how to handle them is usually a major part of the data wrangling phase.\n",
    "\n",
    "In some cases there will be a perfectly valid reason why a value is missing (deathYear for players who are alive).\n",
    "\n",
    "In other cases, the data element may be missing because it is unavailable, or because it was recorded incorrectly, or because the source provided an invalid value to begin with.\n",
    "\n",
    "Real-world data is almost always \"messy\" in this regard.  \n",
    "\n",
    "It is very important that you be aware of what data is missing, which is something you usually have to discover for yourself early in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates, Times, and DateTimes\n",
    "\n",
    "Very often the analysis we want to perform involves some kind of trend, which necessitates working with dates.\n",
    "\n",
    "As you start working with dates, you will quickly discover that the standard \"year,month,day\" representation of dates is problematic.\n",
    "\n",
    "To discover trends, we want to treat our data as a time series, and the Y-M-D representation does not allow us to easily compute the number of time units between two dates if our time unit is days or months.\n",
    "\n",
    "Software designed for data manipulation almost always includes an internal representation of dates and times (and combined date-time values) that gives us a continuous scale.\n",
    "\n",
    "For example, in SAS, a datatime value is the number of seconds since midnight on January 1, 1960.  There are many similar definitions in other software.\n",
    "\n",
    "The advantage of this is that we can just subtract two datetime values and get the number of seconds in that interval, which we can then convert to other units like days (a day being 24 x 3600 or 86,400 seconds).  \n",
    "\n",
    "Converting datetime intervals to months or years is more difficult because not all months are the same length, and there are leapyears. A 'leapyear' is a year with 366 days, the extra day being February 29th.  \n",
    "\n",
    "Years that are multiples of 4 are leapyears, unless they are multiples of 100 and not multiples of 400.  So, 2000 was a leapyear but 1900 was not because 1900 is a multiple of 100, but not 400 and therefore an exception to the \"multiples of 4\" rule.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, working with dates, times, and datetimes is complicated.  \n",
    "\n",
    "As you would expect, pandas provides a comprehensive set of tools for working with dates and times.\n",
    "\n",
    "You can find the full documentation here:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
    "\n",
    "This is a bit of overkill because for now we just want to explore some basic date processing.\n",
    "\n",
    "One of the columns in our Master DataFrame, \"finalGame\", sounds like it would be a date, but as a single value it is probably in one of the commonly used external date formats.\n",
    "\n",
    "There are a number of possibilities for this (YYYY-MM-DD,   YY-MM-DD,   MM-DD-YYYY,   MM-DD-YY,  etc.).\n",
    "\n",
    "The easiest way to discover which one we have is to print a few values of Master.finalGame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master.finalGame[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, it looks like the format is 'YYYY-MM-DD'.  \n",
    "\n",
    "Notice that the type (dtype) of the finalGame column is \"object\".  \n",
    "\n",
    "Unlike most other data analysis software, there is no requirement in pandas that the elements of a column all be of the same type.  \n",
    "\n",
    "If you have more than one data type in a column, pandas uses the smallest class that can represent all of them, usually object.\n",
    "\n",
    "Let's look at a nonmissing finalGame value and see what type it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(Master.finalGame[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the dates are stored as strings of characters.  \n",
    "\n",
    "Strings are just text and have no meaning beyond what you see.  \n",
    "\n",
    "pandas is not aware that these strings represent dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pandas has a function for converting strings to pandas dates, but there is the potential for things to get complicated.\n",
    "\n",
    "We could call this function for every value in the finalGame column, making a provision for handling the exception that will occur when we supply a missing value.\n",
    "\n",
    "It's possible that there are other data types in the column, \"object\" could be anything.  If there are, we have to discover them and what they mean, so we need to spend more time understanding what exactly is in this column.\n",
    "\n",
    "A much better approach is to exploit the facilities of the read_csv() function.  read_csv() has a provision for automatically recognizing dates in the input.\n",
    "\n",
    "It will perform the necessary conversion for dates that are valid, and supply a missing value for those that are not.\n",
    "\n",
    "Best of all, it will happen transparently when we call the read_csv() function, so we don't have to write code, just specify an option on the call to read_csv().\n",
    "\n",
    "You can find the full documentation on read_csv() here:  (as usual, the full documentation is overkill for us)\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "\n",
    "The clean, simple solution to the very common problem of converting dates is an indication that the author of the pandas package, Wes McKinney, had a good understanding of the problems one encounters working with data, and did a good job designing software to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's read Master.csv a third time, but use the parse_dates option of read_csv() to tell pandas that the 'finalGame' column contains dates and we want to convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master = pd.read_csv(\"../../baseballdatabank/core/Master.csv\",   #read Master.csv and designate \"playerID\" as an index\n",
    "                     index_col=[\"playerID\"],parse_dates=['finalGame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Master.finalGame[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dtype for column 'finalGame' is no longer \"object\", but \"datetime64[ns]\", the internal pandas datetime data type.\n",
    "\n",
    "This means the column is now a clean list of dates in the internal pandas datetime representation.\n",
    "\n",
    "One thing worth noting here, even though the first entry displays as 1976-10-03 in both versions of \"Master\", the internal representations are entirely different.\n",
    "\n",
    "When we display the finalGame column from the new \"Master\", pandas automatically recognizes that the 64-bit floating point datetime value will only make sense if it is displayed as a standard 'YYYY-MM-DD' string, but that is NOT what is stored in the new \"Master\".\n",
    "\n",
    "pandas is now \"aware\" that these values represent dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
