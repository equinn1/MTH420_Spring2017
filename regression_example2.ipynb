{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Regression Analysis Using the Boston Housing Data Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "import numpy as np\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(boston.data.shape)\n",
    "print(boston.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=120, suppress=True, edgeitems=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to do multiple regression we need to add a column of 1s for x0\n",
    "x = np.array([np.concatenate((v,[1])) for v in boston.data])\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First 10 elements of the data\n",
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First 10 elements of the response variable\n",
    "print(y[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "linreg.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see predictions for the first 10 instances\n",
    "print (linreg.predict(x[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute RMSE on training data\n",
    "# p = np.array([linreg.predict(xi) for xi in x])\n",
    "p = linreg.predict(x)\n",
    "# Now we can constuct a vector of errors\n",
    "err = abs(p-y)\n",
    "\n",
    "# Let's see the error on the first 10 predictions\n",
    "print (err[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dot product of error vector with itself gives us the sum of squared errors\n",
    "total_error = np.dot(err,err)\n",
    "# Compute RMSE\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "print (rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can view the regression coefficients\n",
    "print('Regression Coefficients: \\n', linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "%matplotlib inline\n",
    "pl.plot(p, y,'ro')\n",
    "pl.plot([0,50],[0,50], 'g-')\n",
    "pl.xlabel('predicted')\n",
    "pl.ylabel('real')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's compute RMSE using 10-fold x-validation\n",
    "kf = KFold(len(x), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    linreg.fit(x[train],y[train])\n",
    "    # p = np.array([linreg.predict(xi) for xi in x[test]])\n",
    "    p = linreg.predict(x[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "    \n",
    "rmse_10cv = np.sqrt(xval_err/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try Ridge Regression:Â¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object with a ridge coefficient 0.5\n",
    "ridge = Ridge(fit_intercept=True, alpha=0.5)\n",
    "\n",
    "# Train the model using the training set\n",
    "ridge.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute RMSE on training data\n",
    "# p = np.array([ridge.predict(xi) for xi in x])\n",
    "p = ridge.predict(x)\n",
    "err = p-y\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "kf = KFold(len(x), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    ridge.fit(x[train],y[train])\n",
    "    p = ridge.predict(x[test])\n",
    "    e = p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "rmse_10cv = np.sqrt(xval_err/len(x))\n",
    "\n",
    "method_name = 'Ridge Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can try different values of alpha and observe the impact on x-validation RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Ridge Regression')\n",
    "print('alpha\\t RMSE_train\\t RMSE_10cv\\n')\n",
    "alpha = np.linspace(.01,20,50)\n",
    "t_rmse = np.array([])\n",
    "cv_rmse = np.array([])\n",
    "\n",
    "for a in alpha:\n",
    "    ridge = Ridge(fit_intercept=True, alpha=a)\n",
    "    \n",
    "    # computing the RMSE on training data\n",
    "    ridge.fit(x,y)\n",
    "    p = ridge.predict(x)\n",
    "    err = p-y\n",
    "    total_error = np.dot(err,err)\n",
    "    rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "    # computing RMSE using 10-fold cross validation\n",
    "    kf = KFold(len(x), n_folds=10)\n",
    "    xval_err = 0\n",
    "    for train, test in kf:\n",
    "        ridge.fit(x[train], y[train])\n",
    "        p = ridge.predict(x[test])\n",
    "        err = p - y[test]\n",
    "        xval_err += np.dot(err,err)\n",
    "    rmse_10cv = np.sqrt(xval_err/len(x))\n",
    "    \n",
    "    t_rmse = np.append(t_rmse, [rmse_train])\n",
    "    cv_rmse = np.append(cv_rmse, [rmse_10cv])\n",
    "    print('{:.3f}\\t {:.4f}\\t\\t {:.4f}'.format(a,rmse_train,rmse_10cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.plot(alpha, t_rmse, label='RMSE-Train')\n",
    "pl.plot(alpha, cv_rmse, label='RMSE_XVal')\n",
    "pl.legend( ('RMSE-Train', 'RMSE_XVal') )\n",
    "pl.ylabel('RMSE')\n",
    "pl.xlabel('Alpha')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To make comparisons across methods easier, let's parametrize the regression methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 0.3\n",
    "for name,met in [\n",
    "        ('linear regression', LinearRegression()),\n",
    "        ('lasso', Lasso(fit_intercept=True, alpha=a)),\n",
    "        ('ridge', Ridge(fit_intercept=True, alpha=a)),\n",
    "        ('elastic-net', ElasticNet(fit_intercept=True, alpha=a))\n",
    "        ]:\n",
    "    met.fit(x,y)\n",
    "    # p = np.array([met.predict(xi) for xi in x])\n",
    "    p = met.predict(x)\n",
    "    e = p-y\n",
    "    total_error = np.dot(e,e)\n",
    "    rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "    kf = KFold(len(x), n_folds=10)\n",
    "    err = 0\n",
    "    for train,test in kf:\n",
    "        met.fit(x[train],y[train])\n",
    "        p = met.predict(x[test])\n",
    "        e = p-y[test]\n",
    "        err += np.dot(e,e)\n",
    "\n",
    "    rmse_10cv = np.sqrt(err/len(x))\n",
    "    print('Method: %s' %name)\n",
    "    print('RMSE on training: %.4f' %rmse_train)\n",
    "    print('RMSE on 10-fold CV: %.4f' %rmse_10cv)\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try to do regression via Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SGD is very senstitive to varying-sized feature values. So, first we need to do feature scaling.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_s = scaler.transform(x)\n",
    "\n",
    "sgdreg = SGDRegressor(penalty='l2', alpha=0.15, n_iter=200)\n",
    "\n",
    "# Compute RMSE on training data\n",
    "sgdreg.fit(x_s,y)\n",
    "p = sgdreg.predict(x_s)\n",
    "err = p-y\n",
    "total_error = np.dot(err,err)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "kf = KFold(len(x), n_folds=10)\n",
    "xval_err = 0\n",
    "for train,test in kf:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x[train])  # Don't cheat - fit only on training data\n",
    "    xtrain_s = scaler.transform(x[train])\n",
    "    xtest_s = scaler.transform(x[test])  # apply same transformation to test data\n",
    "    sgdreg.fit(xtrain_s,y[train])\n",
    "    p = sgdreg.predict(xtest_s)\n",
    "    e = p-y[test]\n",
    "    xval_err += np.dot(e,e)\n",
    "rmse_10cv = np.sqrt(xval_err/len(x))\n",
    "\n",
    "method_name = 'Stochastic Gradient Descent Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the regression implementation from Machine Learning in Action, Chapter 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def standRegres(xArr,yArr):\n",
    "    xMat = np.mat(xArr); yMat = np.mat(yArr).T\n",
    "    xTx = xMat.T*xMat\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        print (\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = xTx.I * (xMat.T*yMat)\n",
    "    return ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = standRegres(x,y)\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ridgeRegres(xArr,yArr,lam=0.2):\n",
    "    xMat = np.mat(xArr); yMat = np.mat(yArr).T\n",
    "    xTx = xMat.T*xMat\n",
    "    denom = xTx + np.eye(np.shape(xMat)[1])*lam\n",
    "    if np.linalg.det(denom) == 0.0:\n",
    "        print (\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = denom.I * (xMat.T*yMat)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_ridge = ridgeRegres(x,y,0.5)\n",
    "print (w_ridge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xMat=np.mat(x)\n",
    "yMat=np.mat(y)\n",
    "yHat = xMat*w_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (yHat[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (yMat.T[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
